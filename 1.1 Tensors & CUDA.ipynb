{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General information\n",
    "PyTorch functions a lot like NumPy. It has a well written documentation and their website contains tutorials aswell. Taking a look at the documentation will often clarify your questions.\n",
    "\n",
    "Link to documentation: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A short recap on ndarray dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we have a table consisting of 4 columns and 5 rows.\n",
    "\n",
    "|time|x|y|z|\n",
    "|:--|:--|:--|:--|\n",
    "|0|5|10|15|\n",
    "|1|6|11|16|\n",
    "|2|7|12|17|\n",
    "|3|8|13|18|\n",
    "|4|9|14|19|\n",
    "\n",
    "We are going to load this table into NumPy and take a look at the dimensions. This is done by loading the table in Pandas and creating a NumPy ndarray from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  x   y   z\n",
       "0     0  5  10  15\n",
       "1     1  6  11  16\n",
       "2     2  7  12  17\n",
       "3     3  8  13  18\n",
       "4     4  9  14  19"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"appendix/example_table.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  5, 10, 15],\n",
       "       [ 1,  6, 11, 16],\n",
       "       [ 2,  7, 12, 17],\n",
       "       [ 3,  8, 13, 18],\n",
       "       [ 4,  9, 14, 19]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = df.to_numpy()\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we have a shape of `rows` by `columns`. Selecting the $y$ value in the 4th row (13) is done by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[3,2] # [row index, column index], counting starts from 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding dimensions\n",
    "Let the above table contain the position of person 1 in the $x, y, z$ direction. Within our dataset we have multiple persons. Each person moves in a different direction. It may be desired to load each single table into one ndarray. One of the requirements to do this is that each table has the same shape. Lets visualize the table of person 1 as cubes. Each cube has the value of the respective element within the table.\n",
    "\n",
    "<centre><img src=\"appendix\\tensor1_axis.png\" width=\"200\"></centre>\n",
    "\n",
    "Notice how the previously selected cell has been highlighted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load 2 more tables and put them sequantially infront of our first table.\n",
    "\n",
    "<centre><img src=\"appendix\\tensors_axis_tables.png\" width=\"300\"></centre>\n",
    "\n",
    "At this point our ndarray has 3 axis, `[table index, row index, column index]`. To access value 13 we use `array[0,3,2]` and to select value 52 within table 3 we use `array[2,3,2]`.\n",
    "\n",
    "It is possible to expand the dimensions further to e.g. `array[block, table, row, column]`. Within this representation each block might contain certain groups of persons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From matrix to tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where NumPy uses vectors and matrices, PyTorch uses tensors. We can intrepret tensors roughly the same way as the n-dimensional matrix shown above. \n",
    "\n",
    "<centre><img src=\"appendix\\matrix_to_tensor.png\" width=\"300\"></centre>\n",
    "\n",
    "To visually give you an idea of the difference, see the above figure. Within this figure a matrix element is changed to a tensor element. This tensor element contains the element value on each side of the cube. In general: \n",
    "\n",
    "\n",
    "<b>NumPy $\\rightarrow$ PyTorch</b>  \n",
    "Scalar $\\rightarrow$ 0D tensor  \n",
    "Vector $\\rightarrow$ 1D tensor  \n",
    "2D Matrix $\\rightarrow$ 2D tensor  \n",
    "3D Matrix $\\rightarrow$ 3D tensor   \n",
    "\n",
    "    \n",
    "    \n",
    "The mathematics of tensors goes beyong the scope of this notebook. If you do want to read more on tensors see: https://en.wikipedia.org/wiki/Tensor#As_multidimensional_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing tensors\n",
    "Construct an empty 5x3 (rows x columns) tensor with data type long.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6069e+16, 3.0704e-41, 1.4982e+29],\n",
       "        [4.5661e-41, 1.6827e+16, 3.0704e-41],\n",
       "        [1.6827e+16, 3.0704e-41, 1.4713e+29],\n",
       "        [4.5661e-41, 2.2177e+24, 4.5661e-41],\n",
       "        [1.3452e-43, 0.0000e+00, 1.1210e-43]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape is just as excpected. Note that the array is not actually empty. See the PyTorch documentation for more details (https://pytorch.org/docs/stable/generated/torch.empty.html#torch.empty)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a tensor directly from a Python array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0,1,2,3,4,5]\n",
    "y = torch.tensor(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch detects the data types automatically and transforms them to its own tensor data type (dtype).  \n",
    "int64 $\\rightarrow$ torch.int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a Tensor directly from a NumPy ndarray.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.array([0,1,2,3,4,5]) # construct ndarray from Python array\n",
    "z = torch.from_numpy(z)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's desirable to manually set the data type of the tensor contents. This is either done by changing the data type of an exsisting tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = z.float() # set the dtype to float32\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = z.double() # converts dtype to float64\n",
    "z.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `.float()` creates a float32. Often this is accurate enough. Be carefull however, sometimes you do really need float64 in scientific computing. If you do not run into memory issues and you do not need to worry about memory allocation, use float64 precision. Better safe than sorry, right?  \n",
    "\n",
    "For more information see the `torch.Tensor` documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our Excel sheet? Lets make it a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5, 10, 15],\n",
       "        [ 1,  6, 11, 16],\n",
       "        [ 2,  7, 12, 17],\n",
       "        [ 3,  8, 13, 18],\n",
       "        [ 4,  9, 14, 19]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"appendix/example_table.xlsx\")\n",
    "ndarray = df.to_numpy()\n",
    "\n",
    "tensor = torch.from_numpy(ndarray)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5, 10, 15],\n",
       "        [ 1,  6, 11, 16],\n",
       "        [ 2,  7, 12, 17],\n",
       "        [ 3,  8, 13, 18],\n",
       "        [ 4,  9, 14, 19]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(pd.read_excel(\"appendix/example_table.xlsx\").to_numpy())\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do tensor operations that comply with the rules of tensor algebra. What does this mean? We can perform operations with or on tensors, so the outcome is another tensor. Lets create two tensors `x` and `y` with shape 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "]) # note the notation [[row1], [row2], [row3]]\n",
    "\n",
    "y = torch.tensor([[10,11,12],[13,14,15],[16,17,18],])\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 11, 12],\n",
       "        [13, 14, 15],\n",
       "        [16, 17, 18]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets perform some tensor operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 13, 15],\n",
       "        [17, 19, 21],\n",
       "        [23, 25, 27]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 13, 15],\n",
       "        [17, 19, 21],\n",
       "        [23, 25, 27]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.add(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 13, 15],\n",
       "        [17, 19, 21],\n",
       "        [23, 25, 27]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three different methods to do addition. Which one is best? Is there a best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping tensors\n",
    "To resize or reshape tensors use `torch.view`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # remember the shape is 3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1), x.view(-1).shape # printing the outputs in one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(9), x.view(9).shape # flatten the tensor, knowing the total tensor entries equals 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add extra dimension\n",
    "\n",
    "3x3 $\\rightarrow$ 1x9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1, 9), x.view(-1, 9).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3x3 \\rightarrow 1x3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]), torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1, 3, 3), x.view(-1, 3, 3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Pytorch instead of NumPy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.youtube.com/embed/-P28LKWTzrI\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f4967ec9e80>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"-P28LKWTzrI\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run tensor calculations GPU\n",
    "One of the beauties of PyTorch is the ability to move tensors to the GPU. This allows for computations to be done on the GPU instead of the CPU. PyTorch uses CUDA to run computations on GPUs. CUDA functions as an interface between regular (CPU) programming and GPU accelerated programming. Note that CUDA only works on NVIDIA GPUs. The connection between Python, PyTorch and a GPU is as follows.\n",
    "\n",
    "Python $\\Leftrightarrow$ PyTorch $\\Leftrightarrow$ c++ $\\Leftrightarrow$ CUDA $\\Leftrightarrow$ GPU\n",
    "\n",
    "Luckily you do not need to be able to work with CUDA yourself. We will be programming in Python and simply tell PyTorch to use one or multiple GPUs for computation.\n",
    "\n",
    "For more information on CUDA see https://developer.nvidia.com/cuda-zone and https://en.wikipedia.org/wiki/CUDA.\n",
    "\n",
    "To monitor hardware usage in a Linux environment use e.g. `top` and `nvidia-smi -l 1` in seperate terminals. The latter is recommended when choosing devices. In a multi-user environment it usefull to choose a GPU that is not in use by someone else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 16 11:08:26 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:05:00.0 Off |                  N/A |\n",
      "| 29%   29C    P8    31W / 250W |     11MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:09:00.0 Off |                  N/A |\n",
      "| 29%   30C    P8    39W / 250W |     11MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 30%   24C    P8     2W / 250W |     11MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:85:00.0 Off |                  N/A |\n",
      "| 30%   28C    P8    20W / 250W |     11MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  On   | 00000000:89:00.0 Off |                  N/A |\n",
      "| 30%   27C    P8    20W / 250W |     11MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning!\n",
    "<font color='red'><b>Make sure to shutdown your notebook (or stop your server in \"Control Panel\") when you are no longer using the GPU! This frees up resources.<b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors on GPU\n",
    "We have seen how to create tensors. By default the computations are performed on CPU. We have to move individual tensors to GPU, before computations using those tensors can be performed on GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of CUDA\n",
    "First we have to check if CUDA is available. This will be the case when your system has CUDA installed and has one or multiple GPUs with CUDA support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA initialisation\n",
    "ngpu = torch.cuda.device_count() # number of available gpus\n",
    "device = torch.device(\"cuda:0\") if (torch.cuda.is_available() and ngpu > 0) else \"cpu\" #cuda:0 for gpu 0, cuda:4 for gpu 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up the functions `torch.cuda.device_count()` and `torch.cuda.is_available()` in the PyTorch documentation to see what they do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the device initialised, we can transfer tensors to our chosen device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors and move them to device\n",
    "x = torch.rand(3,3, device=device)\n",
    "y = torch.rand(3,3).to(device) # Two different methods to move tensor to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7925, 0.1217, 0.9874],\n",
       "        [0.0153, 0.8363, 0.3112],\n",
       "        [0.8710, 0.5111, 0.7765]], device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the tensor output contains the device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4600, 0.4167, 1.3083],\n",
       "        [0.5334, 1.7540, 0.9028],\n",
       "        [1.6701, 1.2647, 1.2917]], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in your resource monitor how these tensors are stored in VRAM (video memory) of the used GPU. To move a tensor from GPU to CPU use the following. Notice how the memory allocation changes from VRAM to RAM. \n",
    "\n",
    "*Windows: resource monitor/task manager, Linux: top / nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6675, 0.2950, 0.3209],\n",
       "        [0.5181, 0.9177, 0.5916],\n",
       "        [0.7992, 0.7535, 0.5152]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x.detach().cpu() # detach x from gpu, move x to cpu\n",
    "b = y.detach().cpu()\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4600, 0.4167, 1.3083],\n",
       "        [0.5334, 1.7540, 0.9028],\n",
       "        [1.6701, 1.2647, 1.2917]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have to be on the same device when performing computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-f985e0a7607a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,3).to(\"cuda:0\")\n",
    "y = torch.rand(3,3).to(\"cpu\")\n",
    "\n",
    "x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you are now able to work with tensors and use them to either perform computations on CPU or on GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop the Jupyter kernel\n",
    "This frees up system resources."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
